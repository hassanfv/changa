{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPwkRQgH7qY2jgejGqbqVpB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hassanfv/changa/blob/master/test_GPU_16_Nov_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfOIGgTowdfi",
        "outputId": "d9dc2782-01a2-41b4-fe03-6e40402d1205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test1.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile test1.cu\n",
        "#include <iostream>\n",
        "#include <ctime>\n",
        "#include <thrust/sort.h>\n",
        "#include <algorithm>\n",
        "using namespace std;\n",
        "\n",
        "__global__ void smoothing(float *x, float *y, float *z, float *dist, float *hres, float *h_previous, int N){\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int stride = blockDim.x;\n",
        "\n",
        "  for(int i = index; i < N; i += stride){\n",
        "    if(i < N){\n",
        "    for(int j = 0; j < N; j++){\n",
        "      float dx = x[j] - x[i];\n",
        "      float dy = y[j] - y[i];\n",
        "      float dz = z[j] - z[i];\n",
        "      dist[i] = sqrt(dx*dx + dy*dy + dz*dz);\n",
        "    }\n",
        "    // ********* MY SORTING ALGORITHM *********\n",
        "    //const int M = N;\n",
        "    float dist_h[10000];\n",
        "    for(int j = 0; j < N; j++){\n",
        "      dist_h[j] = 1.02f;\n",
        "    } \n",
        "    int k = 0;\n",
        "    for(int j = 0; j < N; j++){\n",
        "      if(dist[j] < 3.0f * h_previous[i]){\n",
        "        dist_h[k] = dist[j];\n",
        "        k++;\n",
        "      }\n",
        "    }\n",
        "\n",
        "    int N_h = k - 1;\n",
        "    float temp = 1.5f;\n",
        "    for(int m = 1; m < N_h; m++){\n",
        "      for(int n = N_h - 1; n >= m; n--){\n",
        "        if(dist_h[n] < dist_h[n - 1]){\n",
        "          temp = dist_h[n];\n",
        "          dist_h[n] = dist_h[n -1];\n",
        "          dist_h[n - 1] = temp;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    // ********* END OF MY SORTING ALGORITHM *********\n",
        "    hres[i] = dist_h[64]*0.5;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "\n",
        "  int N = 1e4;\n",
        "  srand(time(NULL));\n",
        "\n",
        "  // Allocate Unified Memory - accessible by CPU and GPU\n",
        "  float *x, *y, *z, *dist, *hres, *h_previous;\n",
        "  cudaMallocManaged(&x, N * sizeof(float));\n",
        "  cudaMallocManaged(&y, N * sizeof(float));\n",
        "  cudaMallocManaged(&z, N * sizeof(float));\n",
        "\n",
        "  cudaMallocManaged(&dist, N * sizeof(float));\n",
        "  cudaMallocManaged(&hres, N * sizeof(float));\n",
        "  \n",
        "  cudaMallocManaged(&h_previous, N * sizeof(float));\n",
        "\n",
        "  // Initializing the arrays on the host\n",
        "  for(int i = 0; i < N; i++){\n",
        "    x[i] = (double)rand()/RAND_MAX;\n",
        "    y[i] = (double)rand()/RAND_MAX;\n",
        "    z[i] = (double)rand()/RAND_MAX;\n",
        "\n",
        "    dist[i] = 1000.0;\n",
        "    hres[i] = 1000.0;\n",
        "    h_previous[i] = 0.10;\n",
        "  }\n",
        "\n",
        "  int blockSize = 512;\n",
        "  int gridSize = (N + blockSize - 1)/blockSize;\n",
        "  smoothing<<<gridSize, blockSize>>>(x, y, z, dist, hres, h_previous, N);\n",
        "\n",
        "  // wait for GPU to finish before accessing the host\n",
        "  cudaDeviceSynchronize();\n",
        "  \n",
        "  thrust::sort(dist, dist + N);\n",
        "\n",
        "  for(int i = 0; i < 70; i++){\n",
        "    cout << hres[i] << endl;\n",
        "  }\n",
        "\n",
        "  cout << \"*******************\" << endl;\n",
        "  //cout << hres[64];\n",
        "  \n",
        "  \n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc test1.cu -o test1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK7Q72r_w-AC",
        "outputId": "28db3cd8-b3b6-47ad-af3e-162a42d1d675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile testx.cu\n",
        "#include <algorithm>\n",
        "#include <iostream>\n",
        "\n",
        "const int N = 3;\n",
        "\n",
        "__global__ void MatAdd(float A[][N], float B[][N], float C[][N])\n",
        "{\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    if (i < N && j < N)\n",
        "        C[i][j] = A[i][j] + B[i][j];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    float* A; cudaMallocManaged(&A, N*N*sizeof(float));\n",
        "    float* B; cudaMallocManaged(&B, N*N*sizeof(float));\n",
        "    float* C; cudaMallocManaged(&C, N*N*sizeof(float));\n",
        "\n",
        "    const float A_vals[N][N]={{1,0,0},{0,1,0},{0,0,1}};\n",
        "    const float B_vals[N][N]={{1,0,0},{0,1,0},{0,0,1}};\n",
        "    float (*C_vals)[N] = reinterpret_cast<float (*)[N]>(C);\n",
        "\n",
        "    std::copy(&A_vals[0][0], &A_vals[0][0] + N*N, A);\n",
        "    std::copy(&B_vals[0][0], &B_vals[0][0] + N*N, B);\n",
        "\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 numBlocks(1, 1);\n",
        "    MatAdd<<<numBlocks, threadsPerBlock>>>( reinterpret_cast<float (*)[N]>(A),\n",
        "                                            reinterpret_cast<float (*)[N]>(B),\n",
        "                                            C_vals );\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    for(int i=0; i<N; i++) {\n",
        "        for(int j=0; j<N; j++) {\n",
        "            std::cout << C_vals[i][j] << \"  \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD8iaqGz1uRR",
        "outputId": "6dab0495-4ae5-4d14-a961-7d06db160c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing testx.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc testx.cu -o testx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSuRlzY28oQt",
        "outputId": "50764e4d-6bff-4699-f3ca-6d9d7b614744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "./testx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3JJrR_w8s7r",
        "outputId": "195a8657-e8fb-4d9a-fce3-19cb4e52bc85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2  0  0  \n",
            "0  2  0  \n",
            "0  0  2  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test1.cu\n",
        "#include <iostream>\n",
        "#include <ctime>\n",
        "#include <thrust/sort.h>\n",
        "#include <algorithm>\n",
        "using namespace std;\n",
        "\n",
        "__global__ void smoothing(float *dist, float *hres, int N, int i){\n",
        "\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "  if(index < N){\n",
        "    float temp = 0.0f;\n",
        "    for(int m = 1; m < N; m++){\n",
        "      for(int n = N - 1; n >= m; n--){\n",
        "        if(dist[n] < dist[n - 1]){\n",
        "          temp = dist[n];\n",
        "          dist[n] = dist[n -1];\n",
        "          dist[n - 1] = temp;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    //if(index == i){\n",
        "    //  hres[i] = dist[64];\n",
        "    hres[index] = 1.0f;\n",
        "    //}\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "\n",
        "  int N = 1e4;\n",
        "  srand(time(NULL));\n",
        "\n",
        "  // Allocate Unified Memory - accessible by CPU and GPU\n",
        "  float *x, *y, *z, *dist, *hres;\n",
        "  cudaMallocManaged(&x, N * sizeof(float));\n",
        "  cudaMallocManaged(&y, N * sizeof(float));\n",
        "  cudaMallocManaged(&z, N * sizeof(float));\n",
        "\n",
        "  cudaMallocManaged(&dist, N * sizeof(float));\n",
        "  cudaMallocManaged(&hres, N * sizeof(float));\n",
        "\n",
        "  // Initializing the arrays on the host\n",
        "  for(int i = 0; i < N; i++){\n",
        "    x[i] = (double)rand()/RAND_MAX;\n",
        "    y[i] = (double)rand()/RAND_MAX;\n",
        "    z[i] = (double)rand()/RAND_MAX;\n",
        "\n",
        "    dist[i] = 1000.0;\n",
        "    hres[i] = 1000.0;\n",
        "  }\n",
        "\n",
        "  for(int i = 0; i < N; i++){\n",
        "\n",
        "    for(int j = 0; j < N; j++){\n",
        "      dist[j] = sqrt((x[j]-x[i])*(x[j]-x[i]) + (y[j]-y[i])*(y[j]-y[i]) + (z[j]-z[i])*(z[j]-z[i]));\n",
        "    }\n",
        "\n",
        "    int blockSize = 256;\n",
        "    int gridSize = (N + blockSize - 1)/blockSize;\n",
        "    smoothing<<<gridSize, blockSize>>>(dist, hres, N, i);\n",
        "\n",
        "    // wait for GPU to finish before accessing the host\n",
        "    cudaDeviceSynchronize();\n",
        "  }\n",
        "\n",
        "  for(int i = 0; i < 10; i++){\n",
        "    cout << dist[i] << endl;\n",
        "  }\n",
        "\n",
        "  cout << \"*******************\" << endl;\n",
        "  \n",
        "  \n",
        "}"
      ],
      "metadata": {
        "id": "eums6hr68vtb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda45809-e219-467b-a56a-954b3dc5a8cf"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc test1.cu -o test1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO4JvXTz-7uX",
        "outputId": "8b800899-f7d9-4b1f-ff0f-636b3509cf64"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "./test1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "JhQSuyF0_FuN",
        "outputId": "9bc9281f-4018-4c96-91f9-62b4e824ad39"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-15f3053acb03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./test1\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m       raise subprocess.CalledProcessError(\n\u001b[0;32m--> 135\u001b[0;31m           returncode=self.returncode, cmd=self.args, output=self.output)\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_repr_pretty_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command './test1\n' died with <Signals.SIGINT: 2>."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Ht6_HRx_Wms"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}